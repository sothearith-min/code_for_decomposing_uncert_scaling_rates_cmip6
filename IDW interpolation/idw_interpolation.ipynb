{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ***Function***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.spatial.distance import cdist\n",
    "from typing import Iterable\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\USER2\\anaconda3\\Lib\\site-packages\\pandas\\core\\arrays\\masked.py:60: UserWarning: Pandas requires version '1.3.6' or newer of 'bottleneck' (version '1.3.5' currently installed).\n",
      "  from pandas.core import (\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy.spatial.distance import cdist\n",
    "import os\n",
    "import xarray as xr\n",
    "import pandas as pd\n",
    "\n",
    "def idw_w(unknown, known, power=2, number_of_neighbours=5):\n",
    "    weights = np.zeros((len(unknown), len(known)))  # Initialize a 2D array to store weights\n",
    "\n",
    "    for i, uk in enumerate(unknown):\n",
    "        distances = cdist([uk], known)  # Compute distances from the unknown point to all known points\n",
    "        closest_indices = distances.argsort()[0, :number_of_neighbours]  # Indices of the closest known points\n",
    "        closest_distances = distances[0, closest_indices]  # Distances to the closest known points\n",
    "        if np.any(closest_distances == 0):\n",
    "            zer_pos = np.where(closest_distances == 0)\n",
    "            weights[i, zer_pos] = 1  # Assign weight 1 to the zero distance\n",
    "            continue\n",
    "        weights[i, closest_indices] = 1 / (closest_distances**power)  # Assign weights to the nearest known points\n",
    "\n",
    "    return weights\n",
    "\n",
    "def idw(data, var, save_path, start_year, stop_year):\n",
    "    data = data.sel(time=slice(str(start_year), str(stop_year)))\n",
    "\n",
    "    if var == \"pr\":\n",
    "        data = data[var] * 86400\n",
    "    elif var == \"tas\":\n",
    "        data = data[var] - 273.15\n",
    "    else:\n",
    "        data = data\n",
    "\n",
    "    expected = pd.read_csv(\https://raw.githubusercontent.com/sothearith-min/code_for_decomposing_uncert_scaling_rates_cmip6/main/IDW%20interpolation/Expected_Location.csv?token=GHSAT0AAAAAACW4IMIQSC343AZ4EVRZYSWGZWVEMHA)\n",
    "    expected = expected[expected.lat > -60]\n",
    "\n",
    "    years = [str(pii) for pii in range(start_year, stop_year + 1)]\n",
    "    dfs_by_year = {}\n",
    "\n",
    "    for year in years:\n",
    "        year_data = data.sel(time=year)\n",
    "        df = year_data.to_dataframe().reset_index()\n",
    "        dfs_by_year[year] = df.dropna()\n",
    "    print(\"Done Reading Data!!!\")\n",
    "\n",
    "    # get weights\n",
    "    weight = idw_w(unknown=expected[[\"lat\", \"lon\"]].values, known=dfs_by_year[str(start_year)][[\"lat\", \"lon\"]].drop_duplicates().values)\n",
    "\n",
    "    for df_name, df in dfs_by_year.items():\n",
    "        df_results = expected[[\"lat\", \"lon\"]].copy()\n",
    "        unique_times = df[\"time\"].unique()\n",
    "        print('start---', df_name)\n",
    "        for time in unique_times:\n",
    "            time_data = df[df['time'] == time][var]\n",
    "            daily_result = []\n",
    "            for w in weight:\n",
    "                if np.sum(w) == 0:\n",
    "                    daily_result.append(np.nan)\n",
    "                else:\n",
    "                    daily_result.append(np.sum(w * time_data) / np.sum(w))\n",
    "            df_results[time] = daily_result\n",
    "        df_results.to_csv(os.path.join(save_path, f\"{df_name}.csv\"), index=False)\n",
    "        print(f\"DataFrame {df_name} saved to {save_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ***Usage***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = xr.open_mfdataset(r\"GCMs-Scenarios.nc\")\n",
    "data = data.sel(time = slice(\"2041-01-01\", \"2090-12-31\"))\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "for y in range(2041, 2090):\n",
    "    idw(data = data,var = \"variable\",   #var = \"pr\" or \"tas\" or [\"hurs\"(for cmip6) and \"rhs\" for cmip5]\n",
    "        save_path= r\"folder_to_save\",\n",
    "        start_year=y, stop_year=y) # we do it for each year to reduce compuational burden"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
